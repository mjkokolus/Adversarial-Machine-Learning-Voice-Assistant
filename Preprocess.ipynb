{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Preprocess.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOzrB7kz2E2Ojk0icxiyca/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"HiC13WX73Zc7","executionInfo":{"status":"error","timestamp":1657033096761,"user_tz":240,"elapsed":7168,"user":{"displayName":"Matthew Kokolus","userId":"01932475957766306177"}},"outputId":"5ee72d3f-05eb-4923-8f78-995d824448f2"},"outputs":[{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-fb4a18379b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mwav_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./audio_files/input.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mmy_waveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_waveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_waveform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mmy_spectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_waveform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-fb4a18379b84>\u001b[0m in \u001b[0;36mget_waveform\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_waveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0maudio_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwaveform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   \"\"\"\n\u001b[0;32m--> 133\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_io_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       return read_file_eager_fallback(\n\u001b[0;32m--> 567\u001b[0;31m           filename, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m    568\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file_eager_fallback\u001b[0;34m(filename, name, ctx)\u001b[0m\n\u001b[1;32m    588\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m   _result = _execute.execute(b\"ReadFile\", 1, inputs=_inputs_flat,\n\u001b[0;32m--> 590\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m    591\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     _execute.record_gradient(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: ./audio_files/input.wav; No such file or directory [Op:ReadFile]"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","\n","def decode_audio(audio_binary):\n","    audio, sample_rate = tf.audio.decode_wav(contents=audio_binary)  # audio: [samples, channels]\n","    return tf.squeeze(audio, axis=-1)\n","\n","\n","def get_waveform(file_path):\n","    audio_binary = tf.io.read_file(file_path)\n","    waveform = decode_audio(audio_binary)\n","    return waveform\n","\n","\n","def get_spectrogram(waveform):\n","    input_len = 16000\n","    if tf.shape(waveform) > input_len:\n","        waveform = waveform[: input_len]  # in this dataset, the max samples of waveform is 16000\n","    elif tf.shape(waveform) < input_len:\n","        zero_padding = tf.zeros(shape=[16000] - tf.shape(waveform), dtype=tf.float32)\n","        waveform = tf.cast(waveform, dtype=tf.float32)  # make sure waveform has the same type as zero padding\n","        waveform = tf.concat([waveform, zero_padding], axis=0)  # waveform with zero padding\n","    spectrogram = tf.signal.stft(signals=waveform, frame_length=255,\n","                                 frame_step=128)  # convert the waveform to a spectrogram via a STFT\n","    ## frame_length\tAn integer scalar Tensor. The window length in samples.\n","    ## frame_step\tAn integer scalar Tensor. The number of samples to step.\n","    spectrogram = tf.abs(spectrogram)  # magnitude + phase. use tf.abs to get rid of phase\n","    spectrogram = spectrogram[..., tf.newaxis]\n","    return spectrogram\n","\n","\n","def plot_spectrogram(spectrogram, ax, debug=False):\n","    if len(spectrogram.shape) > 2:\n","        assert len(spectrogram.shape) == 3\n","        new_spectrogram = np.squeeze(spectrogram, axis=-1)  # (124, 129, 1) -> (124, 129)\n","    # Convert the frequencies to log scale and transpose, so that the time is represented on the x-axis (columns).\n","    log_spec = np.log(new_spectrogram.T + np.finfo(float).eps)\n","    if debug:\n","        print('old spectrogram shape: ', spectrogram.shape)\n","        print('new spectrogram shape: ', new_spectrogram.shape)\n","        print('log spec shape: ', log_spec.shape)\n","        print('spectrogram size: ', np.size(new_spectrogram))\n","    height = log_spec.shape[0]  # 129\n","    width = log_spec.shape[1]  # 124\n","    X = np.linspace(0, np.size(new_spectrogram), num=width, dtype=int)\n","    Y = range(height)\n","    ax.pcolormesh(X, Y, log_spec)\n","\n","\n","def predictModel(model, spectrogram):\n","    listOfData = [spectrogram]\n","    predictData = np.array(listOfData, dtype='float32')\n","    result = model.predict(predictData)\n","    lab = tf.argmax(result, 1)\n","    return lab\n","\n","\n","if __name__ == '__main__':\n","    wav_path = './audio_files/input.wav'. # Change to sample wav input\n","    my_waveform = get_waveform(wav_path)\n","    print(my_waveform.shape)\n","    my_spectrogram = get_spectrogram(my_waveform)\n","    print(my_spectrogram.shape)\n","\n","    # fig, axes = plt.subplots(2, figsize=(12, 8))\n","    # timescale = np.arange(my_waveform.shape[0])\n","    # axes[0].plot(timescale, my_waveform.numpy())\n","    # axes[0].set_title('Waveform')\n","    # axes[0].set_xlim([0, 16000])\n","    #\n","    # plot_spectrogram(my_spectrogram.numpy(), axes[1], debug=True)\n","    # axes[1].set_title('Spectrogram')\n","    # plt.show()\n","\n","    model = tf.saved_model.load(export_dir='F:\\PythonProject\\LearnTF\\official_audio\\Recognizing keywords\\model')\n","    pred = predictModel(model, my_spectrogram)\n","    print(pred)"]}]}